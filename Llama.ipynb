{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8983a092-8fd7-45a8-a591-e954b0232393",
   "metadata": {},
   "source": [
    "# oobabooga/text-generation-webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbe9749c-bbcf-41fc-8f73-9e40bb56f529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T19:01:19.875479Z",
     "iopub.status.busy": "2023-11-22T19:01:19.874899Z",
     "iopub.status.idle": "2023-11-22T19:01:19.878376Z",
     "shell.execute_reply": "2023-11-22T19:01:19.877867Z",
     "shell.execute_reply.started": "2023-11-22T19:01:19.875452Z"
    }
   },
   "outputs": [],
   "source": [
    "LLAMA_ROOT = \"/workspace/llama\"\n",
    "\n",
    "GRADIO_USER = set_user\n",
    "GRADIO_PASS = set_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d88179f-5c64-4e8c-9c63-7cf1c377af7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T18:00:09.247652Z",
     "iopub.status.busy": "2023-11-22T18:00:09.246808Z",
     "iopub.status.idle": "2023-11-22T18:00:09.820715Z",
     "shell.execute_reply": "2023-11-22T18:00:09.819735Z",
     "shell.execute_reply.started": "2023-11-22T18:00:09.247603Z"
    }
   },
   "outputs": [],
   "source": [
    "!sudo useradd user -m --uid 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a9ec218-cdfd-4f2d-90fb-ac1b4f5266c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T18:00:17.996337Z",
     "iopub.status.busy": "2023-11-22T18:00:17.995794Z",
     "iopub.status.idle": "2023-11-22T18:00:18.932080Z",
     "shell.execute_reply": "2023-11-22T18:00:18.931208Z",
     "shell.execute_reply.started": "2023-11-22T18:00:17.996315Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf {LLAMA_ROOT} && mkdir -p {LLAMA_ROOT} && chown user:user -R {LLAMA_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d83197c9-6377-4bf8-b9f2-fd25e02361fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T18:06:51.728386Z",
     "iopub.status.busy": "2023-11-22T18:06:51.727717Z",
     "iopub.status.idle": "2023-11-22T18:06:52.284643Z",
     "shell.execute_reply": "2023-11-22T18:06:52.283823Z",
     "shell.execute_reply.started": "2023-11-22T18:06:51.728359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: Too many arguments.\n",
      "\n",
      "usage: git clone [<options>] [--] <repo> [<dir>]\n",
      "\n",
      "    -v, --verbose         be more verbose\n",
      "    -q, --quiet           be more quiet\n",
      "    --progress            force progress reporting\n",
      "    -n, --no-checkout     don't create a checkout\n",
      "    --bare                create a bare repository\n",
      "    --mirror              create a mirror repository (implies bare)\n",
      "    -l, --local           to clone from a local repository\n",
      "    --no-hardlinks        don't use local hardlinks, always copy\n",
      "    -s, --shared          setup as shared repository\n",
      "    --recursive ...       alias of --recurse-submodules\n",
      "    --recurse-submodules[=<pathspec>]\n",
      "                          initialize submodules in the clone\n",
      "    -j, --jobs <n>        number of submodules cloned in parallel\n",
      "    --template <template-directory>\n",
      "                          directory from which templates will be used\n",
      "    --reference <repo>    reference repository\n",
      "    --reference-if-able <repo>\n",
      "                          reference repository\n",
      "    --dissociate          use --reference only while cloning\n",
      "    -o, --origin <name>   use <name> instead of 'origin' to track upstream\n",
      "    -b, --branch <branch>\n",
      "                          checkout <branch> instead of the remote's HEAD\n",
      "    -u, --upload-pack <path>\n",
      "                          path to git-upload-pack on the remote\n",
      "    --depth <depth>       create a shallow clone of that depth\n",
      "    --shallow-since <time>\n",
      "                          create a shallow clone since a specific time\n",
      "    --shallow-exclude <revision>\n",
      "                          deepen history of shallow clone, excluding rev\n",
      "    --single-branch       clone only one branch, HEAD or --branch\n",
      "    --no-tags             don't clone any tags, and make later fetches not to follow them\n",
      "    --shallow-submodules  any cloned submodules will be shallow\n",
      "    --separate-git-dir <gitdir>\n",
      "                          separate git dir from working tree\n",
      "    -c, --config <key=value>\n",
      "                          set config inside the new repository\n",
      "    --server-option <server-specific>\n",
      "                          option to transmit\n",
      "    -4, --ipv4            use IPv4 addresses only\n",
      "    -6, --ipv6            use IPv6 addresses only\n",
      "    --filter <args>       object filtering\n",
      "    --remote-submodules   any cloned submodules will use their remote-tracking branch\n",
      "    --sparse              initialize sparse-checkout file to include only files at root\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sudo -u user git clone https://github.com/oobabooga/text-generation-webui.git {LLAMA_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c6e25d2-40b0-4c17-978c-25716a166455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T19:01:22.898423Z",
     "iopub.status.busy": "2023-11-22T19:01:22.898140Z",
     "iopub.status.idle": "2023-11-22T19:19:14.219961Z",
     "shell.execute_reply": "2023-11-22T19:19:14.219349Z",
     "shell.execute_reply.started": "2023-11-22T19:01:22.898402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:01:26 WARNING:\u001b[33mThe gradio \"share link\" feature uses a proprietary executable to create a reverse tunnel. Use it with care.\u001b[0m\n",
      "2023-11-22 19:01:31 INFO:\u001b[32mLoading the extension \"gallery\"...\u001b[0m\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://4bece94737a916e287.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "2023-11-22 19:03:06 INFO:\u001b[32mLoading Intel_neural-chat-7b-v3-1...\u001b[0m\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:21<00:00, 10.82s/it]\n",
      "2023-11-22 19:03:34 INFO:\u001b[32mTRUNCATION LENGTH: 32768\u001b[0m\n",
      "2023-11-22 19:03:34 INFO:\u001b[32mINSTRUCTION TEMPLATE: Alpaca\u001b[0m\n",
      "2023-11-22 19:03:34 INFO:\u001b[32mLoaded the model in 27.61 seconds.\u001b[0m\n",
      "Output generated in 11.59 seconds (17.17 tokens/s, 199 tokens, context 396, seed 1046773632)\n",
      "Output generated in 10.68 seconds (18.63 tokens/s, 199 tokens, context 611, seed 784074134)\n",
      "Output generated in 5.89 seconds (17.14 tokens/s, 101 tokens, context 819, seed 1043246651)\n",
      "2023-11-22 19:06:05 INFO:\u001b[32mLoading LeoLM_leo-hessianai-13b...\u001b[0m\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [01:13<00:00, 24.47s/it]\n",
      "2023-11-22 19:07:19 INFO:\u001b[32mTRUNCATION LENGTH: 8192\u001b[0m\n",
      "2023-11-22 19:07:19 INFO:\u001b[32mINSTRUCTION TEMPLATE: Alpaca\u001b[0m\n",
      "2023-11-22 19:07:19 INFO:\u001b[32mLoaded the model in 73.88 seconds.\u001b[0m\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/llama/server.py\", line 238, in <module>\n",
      "    time.sleep(0.5)\n",
      "KeyboardInterrupt\n",
      "Killing tunnel 127.0.0.1:7860 <> https://4bece94737a916e287.gradio.live\n"
     ]
    }
   ],
   "source": [
    "!sudo -u user bash run_llama.sh {LLAMA_ROOT} {GRADIO_USER} {GRADIO_PASS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d8877-0ce2-4395-8b91-47dde6a0d794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
