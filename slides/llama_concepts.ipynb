{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Llama 2 - Konzepte\n",
    "\n",
    "Wir werden uns einige Parameter anschauen die in der [Text Generation WebUI](https://github.com/oobabooga/text-generation-webui.git) von `oobabooga` einstellbar sind. Die wichtigsten besprochenen Parameter und die damit verbundenen Konzepte lassen sich auch bspw. [GPT4All](https://gpt4all.io) übertragen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Der Prompt\n",
    "\n",
    "Vor allen Parametern hat der Prompt wohl den größten Einfluss auf die Art und Weise der Ausgabe.\n",
    "Prompts schreiben ist eine Wissenschaft für sich, die teils schon als eigenständige Tätigskeits- bzw. Berufsbezeichnung genutzt wird (vgl. *Prompt Engineer*).\n",
    "Einstiegspunkte finden sich viele. Zwei Möglichkeiten sind der [Prompt Engineering Guide](https://www.promptingguide.ai/) von DAIR.AI und die Azure Dokumentation zu [Prompt engineering techniques\n",
    "](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering) von Microsoft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parameters\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    id0([Es])\n",
    "    id1([war])\n",
    "    id2.1([einmal])\n",
    "    id2.2([nicht])\n",
    "    id2.3([schon])\n",
    "    id2.4([Essenszeit])\n",
    "\n",
    "    id0 --> id1\n",
    "    id1 --0.4--> id2.1\n",
    "    id1 --0.3--> id2.2\n",
    "    id1 --0.2--> id2.3\n",
    "    id1 --0.1--> id2.4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "**Token**: Ein Wort oder ein Teil eines Wortes, in etwa 4 Zeichen, teils große Abweichungen zwischen verschiedenen Sprachen[¹](https://www.artfish.ai/p/all-languages-are-not-created-tokenized).\n",
    "\n",
    "```\n",
    "Wie | viele | Tok | ens | hat | dieser | Sat | z | ?\n",
    "```\n",
    "\n",
    "<div style=\"margin-top: 1rem;\">\n",
    "   <img src=\"images/token_distribution.png\" width=\"500\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    id0([Es])\n",
    "    id1([war])\n",
    "    id2.2([nicht])\n",
    "    id2.1([einmal])\n",
    "    id2.3([schon])\n",
    "    id2.4([Essenszeit])\n",
    "    \n",
    "    id3.1([vor])\n",
    "    id3.2([in])\n",
    "    id3.3([Sonntag])\n",
    "\n",
    "    id0 --> id1\n",
    "    id1 --0.4--> id2.1\n",
    "    id1 --0.2--> id2.3\n",
    "    id1 --0.3--> id2.2\n",
    "    id1 --0.1--> id2.4\n",
    "    id2.1 --0.5--> id3.1\n",
    "    id2.1 --0.45--> id3.2\n",
    "    id2.1 --0.05--> id3.3\n",
    "\n",
    "    style id2.1 stroke:#f00\n",
    "    style id3.1 stroke:#f00\n",
    "    style id2.2 stroke:#0f0\n",
    "    style id2.4 color:#888\n",
    "```\n",
    "\n",
    "* **max_new_tokens**: Ausgabebegrenzung, kleine Werte sorgen für wenig generierten Text, hohe Werte für ausführliche Ausgaben.\n",
    "* **temperature**: Zufallsfaktor, legt fest, wie oft 'unwahrscheinliche' Tokens genutzt werden. Ein Wert von 0 nutzt immer das wahrscheinlichste Token und führt dazu zu einer relativ vorhersehbaren bzw. deterministischen Ausgabe. Werte höher als 0.5 sind eher kreativ.\n",
    "* **top_p**: Es werden nur Tokens verwendet, deren addierte Wahrscheinlichkeit diesen Wert nicht überschreitet.\n",
    "* **min_p**: Tokens mit geringerer Wahrscheinlichkeit (relativ zum wahrscheinlichsten Token) werden nicht berücksichtigt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    id0([Es])\n",
    "    id1([war])\n",
    "    id2.2([nicht])\n",
    "    id2.1([einmal])\n",
    "    id2.3([schon])\n",
    "    id2.4([Essenszeit])\n",
    "    \n",
    "    id3.1([vor])\n",
    "    id3.2([in])\n",
    "    id3.3([Sonntag])\n",
    "\n",
    "    id0 --> id1\n",
    "    id1 --0.4--> id2.1\n",
    "    id1 --0.2--> id2.3\n",
    "    id1 --0.3--> id2.2\n",
    "    id1 --0.1--> id2.4\n",
    "    id2.1 --0.5--> id3.1\n",
    "    id2.1 --0.45--> id3.2\n",
    "    id2.1 --0.05--> id3.3\n",
    "\n",
    "    style id0 color:#888\n",
    "    style id2.3 color:#888\n",
    "    style id2.4 color:#888\n",
    "```\n",
    "\n",
    "* **top_k**: ähnlich zu *top_p*, nutzt die `k` wahrscheinlichsten Ausgaben\n",
    "* **repetition_penalty**: *Strafterm* für die Wiederholung (die Wiederholung, die Wiederholung) von Tokenfolgen, senkt damit die Auftrittswahrscheinlichkeit\n",
    "* **context_length**: Anzahl der Token die Modell verarbeiten kann, ältere Tokens werden verworfen, je nach Modell vorgegeben oder anpassbar\n",
    "* **seed**: Ausgangswert für Pseudozufallsberechnungen, gleicher Seed führt bei gleichen Parametern und Eingaben zu gleichen Ergebnissen (bei deterministischen Modellen/Bibliotheken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Textgenerierung\n",
    "\n",
    "Welche Interaktionsmöglichkeiten bietet Llama bzw. die WebUI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fortschreiben\n",
    "\n",
    "Text weiterschreiben\n",
    "\n",
    "```\n",
    "Es war einmal ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Chat\n",
    "\n",
    "\"Rollenspiel\" mit Sprachmodellen.\n",
    "\n",
    "```\n",
    "Du heißt 'Llama' und bist sehr hilfsbereit.\n",
    "Du bist stehts freundlich und bleibst immer höflich.\n",
    "Eine Person namens 'User' kommt auf dich zu und möchte mit dir reden.\n",
    "\n",
    "User: Hallo Llama!\n",
    "Llama: ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Characters\n",
    "\n",
    "Neben der \"Standard-Persona\" eines geladenen Modelles, kann ein \"Characterprofil\" übergeben werden, um die Ausgaben und den Ausgabestil zu personalisieren.\n",
    "Die Website [Botprompts.net](https://botprompts.net) bietet eine Sammlung an Personas an, die direkt in die WebUI geladen werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fragen und Antworten (Q & A)\n",
    "\n",
    "\"Rollenspiel\" als Assistenzsystem, welches Anweisungen befolgen kann, teils unter dier Zuhilfename von vorher übergebenen Dokumenten.\n",
    "\n",
    "```\n",
    "Du heißt 'Llama' und bist ein hilfsbereites Assistenzsystem.\n",
    "Du kennst dich besonders gut mit einfachen und schneller Kochrezepten aus.\n",
    "Wenn ein User dich nach einem Rezept fragt, gibst du als erstes eine Zutatenliste mit Mengenangaben aus und dann eine kurze und prägnante Aufstellung aller notwendingen Kochschritte.\n",
    "\n",
    "Dein Kochbuch: {context}\n",
    "\n",
    "Anweisung: {user_input}\n",
    "\n",
    "Das Kochrezept als Ausgabe:\n",
    "```\n",
    "\n",
    "Die WebUI unterstützt das Übergeben von Dokumenten für QA-Szenarien bisher nicht. Alternativ kann hier GPT4All genutzt werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finetuning vs LoRA\n",
    "\n",
    "<div>\n",
    "   <img src=\"images/dnn.png\" width=\"600\">\n",
    "   <div><a href=\"https://commons.wikimedia.org/wiki/File:Example_of_a_deep_neural_network.png\">CC BY 4.0</a></div>\n",
    "</div>\n",
    "\n",
    "\n",
    "* **Finetuning** beschreibt die Anpassung eines DNN/Modells durch Nachtrainieren. Dabei werden Schichtern inner des neuronalen Netzes 'eingefroren' und Änderungen nur auf den Ebenen (nahe der Ausgabe) durchgeführt.\n",
    "* **LoRA** oder *Low-Rank Adaptation of Large Language Models* verändert das zu trainierende Modell *nicht*, sondern erstellt zwei 'einfachere' Matrizen, welche nur die Änderungen der Orginalgewichte beinhaltet (*update matrices*).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
