{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Llama 2 - Concepts\n",
    "\n",
    "* https://github.com/oobabooga/text-generation-webui/wiki\n",
    "* https://www.promptingguide.ai/\n",
    "* https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parameters\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    id0([Es])\n",
    "    id1([war])\n",
    "    id2.1([einmal])\n",
    "    id2.2([nicht])\n",
    "    id2.3([schon])\n",
    "    id2.4([Essenszeit])\n",
    "\n",
    "    id0 --> id1\n",
    "    id1 --0.4--> id2.1\n",
    "    id1 --0.3--> id2.2\n",
    "    id1 --0.2--> id2.3\n",
    "    id1 --0.1--> id2.4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "**Token**: Ein Wort oder ein Teil eines Wortes, in etwa 4 Zeichen, teils große Abweichungen zwischen verschiedenen Sprachen[¹](https://www.artfish.ai/p/all-languages-are-not-created-tokenized).\n",
    "\n",
    "```\n",
    "Wie | viele | Tok | ens | hat | dieser | Sat | z | ?\n",
    "```\n",
    "\n",
    "![](images/token_distribution.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    id0([Es])\n",
    "    id1([war])\n",
    "    id2.2([nicht])\n",
    "    id2.1([einmal])\n",
    "    id2.3([schon])\n",
    "    id2.4([Essenszeit])\n",
    "    \n",
    "    id3.1([vor])\n",
    "    id3.2([in])\n",
    "    id3.3([Sonntag])\n",
    "\n",
    "    id0 --> id1\n",
    "    id1 --0.4--> id2.1\n",
    "    id1 --0.2--> id2.3\n",
    "    id1 --0.3--> id2.2\n",
    "    id1 --0.1--> id2.4\n",
    "    id2.1 --0.5--> id3.1\n",
    "    id2.1 --0.45--> id3.2\n",
    "    id2.1 --0.05--> id3.3\n",
    "\n",
    "    style id2.1 stroke:#f00\n",
    "    style id3.1 stroke:#f00\n",
    "    style id2.2 stroke:#0f0\n",
    "    style id2.4 color:#888\n",
    "```\n",
    "\n",
    "* **max_new_tokens**: Ausgabebegrenzung, kleine Werte sorgen für wenig generierten Text, hohe Werte für ausführliche Ausgaben.\n",
    "* **temperature**: Zufallsfaktor, legt fest, wie oft 'unwahrscheinliche' Tokens genutzt werden. Ein Wert von 0 nutzt immer das wahrscheinlichste Token und führt dazu zu einer relativ vorhersehbaren bzw. deterministischen Ausgabe. Werte höher als 0.5 sind eher kreativ.\n",
    "* **top_p**: Es werden nur Tokens verwendet, deren addierte Wahrscheinlichkeit diesen Wert nicht überschreitet.\n",
    "* **min_p**: Tokens mit geringerer Wahrscheinlichkeit (relativ zum wahrscheinlichsten Token) werden nicht berücksichtigt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    id0([Es])\n",
    "    id1([war])\n",
    "    id2.2([nicht])\n",
    "    id2.1([einmal])\n",
    "    id2.3([schon])\n",
    "    id2.4([Essenszeit])\n",
    "    \n",
    "    id3.1([vor])\n",
    "    id3.2([in])\n",
    "    id3.3([Sonntag])\n",
    "\n",
    "    id0 --> id1\n",
    "    id1 --0.4--> id2.1\n",
    "    id1 --0.2--> id2.3\n",
    "    id1 --0.3--> id2.2\n",
    "    id1 --0.1--> id2.4\n",
    "    id2.1 --0.5--> id3.1\n",
    "    id2.1 --0.45--> id3.2\n",
    "    id2.1 --0.05--> id3.3\n",
    "\n",
    "    style id0 color:#888\n",
    "    style id2.3 color:#888\n",
    "    style id2.4 color:#888\n",
    "```\n",
    "\n",
    "* **top_k**: Similar to top_p, but select instead only the top_k most likely tokens. Higher value = higher range of possible random results.\n",
    "* **repetition_penalty**: Penalty factor for repeating prior tokens. 1 means no penalty, higher value = less repetition, lower value = more repetition.\n",
    "* **context_length**:  The (predefined) number of tokens a language model can process at once.  It is the maximum length of the input sequence. It’s like the memory or attention span of the model.\n",
    "* **seed**: Ausgangswert für Pseudozufallsberechnungen. Gleicher Seed führ bei gleichen Parametern und Eingaben zu gleichem Ergebnis (bei deterministischen Modellen/Bibliotheken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Textgenerierung\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standardfall\n",
    "\n",
    "Schreibe den Text weiter!\n",
    "\n",
    "```\n",
    "Es war einmal ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Chat\n",
    "\n",
    "\"Rollenspiel\" mit Sprachmodellen.\n",
    "\n",
    "```\n",
    "Du heißt 'Llama' und bist sehr hilfsbereit.\n",
    "Du bist stehts freundlich und bleibst immer höflich.\n",
    "Eine Person namens 'User' kommt auf dich zu und möchte mit dir reden.\n",
    "\n",
    "User: Hallo Llama!\n",
    "Llama: ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Characters\n",
    "\n",
    "* https://botprompts.net/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fragen und Antworten (Q & A)\n",
    "\n",
    "\"Rollenspiel\" mit Anweisungen.\n",
    "\n",
    "```\n",
    "Du heißt 'Llama' und bist ein hilfsbereites Assistenzsystem.\n",
    "Du kennst dich besonders gut mit einfachen und schneller Kochrezepten aus.\n",
    "Wenn ein User dich nach einem Rezept fragt, gibst du als erstes eine Zutatenliste mit Mengenangaben aus und dann eine kurze und prägnante Aufstellung aller notwendingen Kochschritte.\n",
    "\n",
    "User: Hallo Llama, kannst du mir sagen, wie man Mac and Cheese zubereitet?\n",
    "Llama:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WikiQuote [de] - Zitate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenquelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
